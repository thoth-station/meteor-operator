---
apiVersion: tekton.dev/v1beta1
kind: Pipeline
metadata:
  name: cnbi-gitrepo
  annotations:
    meteor.zone/pipeline: "true"
    shower.meteor.zone/button-label: Run code in JupyterHub
spec:
  description: Build an image suitable for experiments in JupyterHub, including all dependencies resolved by Thoth Station
  params:
    - name: url
      type: string
    - name: ref
      type: string
      default: ""
    - name: ownerReferences
      default: "[]"

  workspaces:
    - name: data
    - name: sslcertdir
      optional: true

  tasks:
    - name: git-clone
      taskRef:
        name: git-clone
        kind: ClusterTask
      workspaces:
        - name: output
          workspace: data
      params:
        - name: url
          value: $(params.url)
        - name: revision
          value: $(params.ref)
        - name: subdirectory
          value: repo

    - name: generate
      taskRef:
        name: generate-jupyterhub
      runAfter:
        - git-clone
      workspaces:
        - name: data
          workspace: data
      params:
        - name: url
          value: $(params.url)

    - name: buildah
      taskRef:
        name: buildah
      runAfter:
        - generate
      workspaces:
        - name: data
          workspace: data
        - name: sslcertdir
          workspace: sslcertdir
      params:
        - name: IMAGE
          value: image-registry.openshift-image-registry.svc:5000/$(context.pipelineRun.namespace)/$(context.pipelineRun.name)
        - name: BASE_IMAGE
          value: $(tasks.generate.results.baseImage)

    - name: resolve-owner-reference
      taskRef:
        name: resolve-owner-reference
      params:
        - name: ownerReferences
          value: $(params.ownerReferences)
        - name: namespace
          value: $(context.pipelineRun.namespace)

    - name: create-image-stream
      taskRef:
        name: openshift-client
        kind: ClusterTask
      runAfter:
        - buildah
        - resolve-owner-reference
      params:
        - name: SCRIPT
          value: |
            cat <<EOM | oc apply -f -
            ---
            kind: ImageStream
            apiVersion: image.openshift.io/v1
            metadata:
              annotations:
                opendatahub.io/notebook-image-name: $(context.pipelineRun.name)
                opendatahub.io/notebook-image-url: $(params.url)
              name: $(context.pipelineRun.name)
              namespace: $(context.pipelineRun.namespace)
              labels:
                opendatahub.io/notebook-image: 'true'
            spec:
              lookupPolicy:
                local: true
              tags:
                - name: latest
            EOM

            oc patch -n $(context.pipelineRun.namespace) imagestream/$(context.pipelineRun.name) --type='merge' -p='$(tasks.resolve-owner-reference.results.patch)'

  finally:
    - name: push-metrics
      taskRef:
        name: send-metrics
      workspaces:
        - name: data
          workspace: data
      params:
        - name: pipeline
          value: $(context.pipeline.name)
        - name: pipelineRun
          value: $(context.pipelineRun.name)
---
apiVersion: tekton.dev/v1beta1
kind: Task
metadata:
  name: buildah
  labels:
    app.kubernetes.io/version: "0.2"
  annotations:
    tekton.dev/categories: Image Build
    tekton.dev/pipelines.minVersion: "0.17.0"
    tekton.dev/tags: image-build
spec:
  description: >-
    Buildah task builds source into a container image and then pushes it to a
    container registry.

    Buildah Task builds source into a container image using Project Atomic's
    Buildah build tool.It uses Buildah's support for building from Dockerfiles,
    using its buildah bud command.This command executes the directives in the
    Dockerfile to assemble a container image, then pushes that image to a
    container registry.
  params:
    - description: Reference of the image buildah will produce.
      name: IMAGE
      type: string
    - default: >-
        registry.redhat.io/rhel8/buildah@sha256:6a68ece207bc5fd8db2dd5cc2d0b53136236fb5178eb5b71eebe5d07a3c33d13
      description: The location of the buildah builder image.
      name: BUILDER_IMAGE
      type: string
    - default: vfs
      description: Set buildah storage driver
      name: STORAGE_DRIVER
      type: string
    - default: ./Dockerfile
      description: Path to the Dockerfile to build.
      name: DOCKERFILE
      type: string
    - default: .
      description: Path to the directory to use as context.
      name: CONTEXT
      type: string
    - default: "true"
      description: >-
        Verify the TLS on the registry endpoint (for push/pull to a non-TLS
        registry)
      name: TLSVERIFY
      type: string
    - default: oci
      description: "The format of the built container, oci or docker"
      name: FORMAT
      type: string
    - default: ""
      description: Extra parameters passed for the build command when building images.
      name: BUILD_EXTRA_ARGS
      type: string
    - default: ""
      description: Extra parameters passed for the push command when pushing images.
      name: PUSH_EXTRA_ARGS
      type: string
    - name: BASE_IMAGE

  workspaces:
  - name: data
  - name: sslcertdir
    optional: true
    mountPath: /workspace/sslcertdir
  results:
    - name: IMAGE_DIGEST
      description: Digest of the image just built.
    - name: IMAGE_URL
      description: URL  of the built Image.

  steps:
    - image: $(params.BUILDER_IMAGE)
      name: build
      workingDir: $(workspaces.data.path)
      resources:
        limits:
          cpu: "2"
          memory: "8Gi"
        requests:
          cpu: "1"
          memory: "2Gi"
      script: |
        mkdir -p .tekton_metrics
        touch .tekton_metrics/images
        start=`date +%s`

        [[ "$(workspaces.sslcertdir.bound)" == "true" ]] && CERT_DIR_FLAG="--cert-dir $(workspaces.sslcertdir.path)"
        buildah ${CERT_DIR_FLAG}  --storage-driver=$(params.STORAGE_DRIVER) bud \
          $(params.BUILD_EXTRA_ARGS) --format=$(params.FORMAT) \
          --tls-verify=$(params.TLSVERIFY) --no-cache \
          -f $(params.DOCKERFILE) -t $(params.IMAGE) $(params.CONTEXT)

        end=`date +%s`

        touch .tekton_metrics/image_build_success
        echo "$((end-start))" > .tekton_metrics/image_build_duration
      volumeMounts:
        - mountPath: /var/lib/containers
          name: varlibcontainers

    - name: send-for-build-analysis
      image: quay.io/thoth-station/s2i-thoth-dev:latest
      workingDir: $(workspaces.data.path)
      env:
        - name: base_image
          value: $(params.BASE_IMAGE)
        - name: namespace
          value: $(context.taskRun.namespace)
        - name: image
          value: $(params.IMAGE)
      script: |
        #!/opt/app-root/bin/python
        import requests
        import os
        import time
        import json
        from pathlib import Path

        from thoth.common import OpenShift

        POD_ID = os.getenv("HOSTNAME")
        NAMESPACE = os.getenv("namespace")
        BASE_IMAGE = os.getenv("base_image")
        IMAGE = os.getenv("image")

        OPENSHIFT = OpenShift()
        URL_HOST = OPENSHIFT.openshift_api_url
        URL_TOKEN = OPENSHIFT.token

        STATUS_ENDPOINT = f"{URL_HOST}/api/v1/namespaces/{NAMESPACE}/pods/{POD_ID}"
        LOG_ENDPOINT = f"{URL_HOST}/api/v1/namespaces/{NAMESPACE}/pods/{POD_ID}/log"

        BUILD_PARAMS = {"container": "step-build"}
        GET_HEADERS = {
            "Authorization": "Bearer {}".format(URL_TOKEN),
            "Content-Type": "application/json",
        }

        URL = "https://khemenu.thoth-station.ninja/api/v1/build-analysis"


        def check_build_status():
            response = requests.get(
                STATUS_ENDPOINT, headers=GET_HEADERS, verify=False, params=BUILD_PARAMS,
            )
            context = response.json()
            return next(
                filter(
                    lambda x: x["name"] == "step-build",
                    response.json().get("status", {}).get("containerStatuses", {}),
                ),
                {"state": "running"},
            )


        try:
            Path(".tekton_metrics/image_build_log_analysis").touch()

            if "thoth-station" not in BASE_IMAGE:
                Path(".tekton_metrics/image_build_log_analysis_skipped").touch()
                raise ValueError(
                    f"Base image '{BASE_IMAGE}' is not suitable for analysis."
                )

            while context := check_build_status():
                if "running" in context["state"]:
                    print("Waiting for container step-build, It is still running...")
                    time.sleep(30)
                    continue
                elif "terminated" in context["state"]:
                    print("Build Step is completed.")
                    break
                else:
                    raise ValueError(f"Build step has failed: {context}")

            log_response = requests.get(
                LOG_ENDPOINT, headers=GET_HEADERS, verify=False, params=BUILD_PARAMS,
            )
            response = requests.post(
                URL,
                json={
                    "base_image": BASE_IMAGE,
                    "build_log": {
                        "apiversion": "",
                        "kind": '"BuildLog"\n',
                        "log": json.dumps(log_response.text),
                        "metadata": "string",
                    },
                    "output_image": IMAGE,
                },
            )
            if response.status_code == 202:
                print("Successfully submitted for build analysis.")
                Path(".tekton_metrics/image_build_log_analysis_success").touch()

            else:
                Path(".tekton_metrics/image_build_log_analysis_failure").touch()
                raise ValueError(
                    f"Submit attempt for build analysis has Failed: {response.text}"
                )

        except Exception as e:
            print("Failed to submit for build analysis.")
            print("Status Response:", e)

    - image: $(params.BUILDER_IMAGE)
      name: push
      workingDir: $(workspaces.data.path)
      script: |
        start=`date +%s`

        [[ "$(workspaces.sslcertdir.bound)" == "true" ]] && CERT_DIR_FLAG="--cert-dir $(workspaces.sslcertdir.path)"
        buildah ${CERT_DIR_FLAG} --storage-driver=$(params.STORAGE_DRIVER) push \
          $(params.PUSH_EXTRA_ARGS) --tls-verify=$(params.TLSVERIFY) \
          --digestfile $(workspaces.data.path)/image-digest $(params.IMAGE) \
          docker://$(params.IMAGE)

        end=`date +%s`
        touch .tekton_metrics/image_push_success_total
        echo "$((end-start))" > .tekton_metrics/image_push_duration
      volumeMounts:
        - mountPath: /var/lib/containers
          name: varlibcontainers
      resources:
        limits:
          cpu: "2"
          memory: "8Gi"
        requests:
          cpu: "1"
          memory: "2Gi"

    - name: send-for-image-analysis
      image: quay.io/thoth-station/s2i-thoth-dev:latest
      workingDir: $(workspaces.data.path)
      env:
        - name: image
          value: $(params.IMAGE)
      script: |
        #!/opt/app-root/bin/python
        import requests
        import os
        from pathlib import Path

        URL = "https://khemenu.thoth-station.ninja/api/v1/analyze?"

        Path(".tekton_metrics/image_analysis").touch()
        params = {
            "image": os.getenv("image"),
            "environment_type": "runtime",
            "verify_tls": True,
        }

        try:
            response = requests.post(
                URL, headers={"Content-type": "application/json"}, params=params,
            )
            if response.status_code == 202:
                Path(".tekton_metrics/image_analysis_success").touch()
                print("Successfully submitted for image analysis.")
            else:
                raise ValueError(response.text)
        except Exception as e:
            Path(".tekton_metrics/image_analysis_failure").touch()
            print("Submit attempt for image analysis has Failed.")
            print("Reason: {}".format(e))

      volumeMounts:
        - name: varlibcontainers
          mountPath: /var/lib/containers

    - name: digest-to-results
      image: $(params.BUILDER_IMAGE)
      workingDir: $(workspaces.data.path)
      script: |
        cat image-digest | tee /tekton/results/IMAGE_DIGEST
        echo $(params.IMAGE) > /tekton/results/IMAGE_URL

  volumes:
    - name: varlibcontainers
      emptyDir: {}
---
apiVersion: tekton.dev/v1beta1
kind: Task
metadata:
  name: generate-jupyterhub
spec:
  params:
    - name: DEFAULT_PYTHON_VERSION
      description: Which Python version to use as a default base image if unable to infer better
      default: "3.8"
    - name: url

  results:
    - name: baseImage

  workspaces:
    - name: data

  steps:
    - name: get-base-image
      image: quay.io/thoth-station/s2i-thoth-dev:latest
      workingDir: $(workspaces.data.path)/repo
      env:
        - name: DEFAULT_VERSION
          value: $(params.DEFAULT_PYTHON_VERSION)
        - name: BASE_IMAGE_RESULT
          value: $(results.baseImage.path)
      script: |
        #!/opt/app-root/bin/python
        import os
        import json
        import yaml
        import sys

        from pipfile import Pipfile

        # List all supported base images here ordered by priority (most favoured on top)
        IMAGE_LIST = [
            ("3.8-elyra", "quay.io/thoth-station/s2i-elyra-custom-notebook", "latest"),
            ("3.8", "quay.io/operate-first/s2i-sre-notebook", "latest"),
            ("3.8", "quay.io/thoth-station/s2i-custom-py38-notebook", "latest"),
            ("3.6", "quay.io/thoth-station/s2i-custom-notebook", "latest"),
        ]

        DEFAULT_IMAGE = next(
            iter(f"{i}:{t}" for v, i, t in IMAGE_LIST if v == os.getenv("DEFAULT_VERSION")), ""
        )


        def python_from_pipfile(path):
            pipfile_path = os.path.join(path, "Pipfile")
            if not os.path.isfile(pipfile_path):
                return ""

            parsed = Pipfile.load(filename=pipfile_path)
            version = parsed.data["_meta"].get("requires", {}).get("python_version", "")

            if "elyra" in parsed.data["default"]:
                return version + "-elyra"
            else:
                return version


        def analyze_overlay(overlay, root):
            print(f'Analyzed overlay \'{overlay.get("name", "")}\'')
            version = python_from_pipfile(os.path.join(root, overlay.get("name", "")))
            base_image = overlay.get("build", {}).get("base-image")

            print(f" - Python version used:   {version}")
            print(f" - Preferred base image:  {base_image}")

            return version, base_image


        def guess_best_match(analyzed_overlays):
            for version, base, tag in IMAGE_LIST:
                match = f"{base}:{tag}"
                for o in analyzed_overlays:
                    if base in o[1].split(":")[0]:
                        return o[1]
                        break
                if version in [o[0] for o in analyzed_overlays]:
                    return match
                    break

            return DEFAULT_IMAGE


        def write_output(answer):
            print("\nBest matching base image: " + answer)
            with open(os.getenv("BASE_IMAGE_RESULT"), "w+") as output:
                output.write(answer)


        def fallback():
            print("Missing or empty aicoe-ci.yaml, analyzing Pipfile only.")
            version = python_from_pipfile(".")
            answer = guess_best_match([(version, "", "")])
            write_output(answer)
            sys.exit(0)


        if not os.path.isfile(".aicoe-ci.yaml"):
            fallback()

        with open(".aicoe-ci.yaml", "r") as stream:
            conf = yaml.safe_load(stream)

        if not isinstance(conf, dict):
            fallback()
        elif conf.get("overlays"):
            overlays, root = (conf.get("overlays"), conf.get("overlays_dir"))
        elif conf.get("build"):
            overlays, root = ([conf], "")
        else:
            fallback()

        accumulator = [analyze_overlay(overlay, root) for overlay in overlays]
        answer = guess_best_match(accumulator)
        write_output(answer)

    - name: generate
      image: quay.io/openshift-pipeline/s2i:nightly
      workingDir: $(workspaces.data.path)
      script: |
        REPONAME=$(basename $(params.url) .git)
        BASE_IMAGE=$(cat $(results.baseImage.path))

        /usr/local/bin/s2i \
        --loglevel=0 \
        build \
        ./repo \
        "$BASE_IMAGE" \
        --as-dockerfile \
        ./Dockerfile \
        --scripts-url="image:///opt/app-root/builder" \
        --env=UPGRADE_PIP_TO_LATEST=1 \
        --env=THAMOS_RUNTIME_ENVIRONMENT="" \
        --env=THOTH_ADVISE=0 \
        --env=THOTH_ERROR_FALLBACK=1 \
        --env=THOTH_DRY_RUN=1 \
        --env=THAMOS_DEBUG=0 \
        --env=THAMOS_VERBOSE=1 \
        --env=THOTH_PROVENANCE_CHECK=0 \
        --env=GIT_REPO_URL=$(params.url) \
        --env=GIT_REPO_NAME="$REPONAME"
---
apiVersion: tekton.dev/v1beta1
kind: Task
metadata:
  name: resolve-owner-reference
spec:
  params:
    - name: ownerReferences
    - name: namespace
  results:
    - name: patch
  steps:
    - name: resolve-owner-reference
      image: quay.io/thoth-station/s2i-thoth-dev:latest
      env:
        - name: OWNER_REFERENCES
          value: $(params.ownerReferences)
        - name: NAMESPACE
          value: $(params.namespace)
        - name: RESULT
          value: $(results.patch.path)
      script: |
        #!/opt/app-root/bin/python
        import json
        import os

        OWNER_REFERENCES = json.loads(os.getenv("OWNER_REFERENCES"))
        TARGET_REFERENCE = next(
            filter(lambda x: x["namespace"] == os.getenv("NAMESPACE"), OWNER_REFERENCES), {}
        )

        PATCH = {"metadata": {"ownerReferences": [TARGET_REFERENCE]}}
        with open(os.getenv("RESULT"), "w") as f:
            json.dump(PATCH, f)
---
apiVersion: tekton.dev/v1beta1
kind: Task
metadata:
  name: send-metrics
spec:
  params:
    - name: pipeline
    - name: pipelineRun
  workspaces:
    - name: data
  steps:
    - name: send-metrics
      image: quay.io/thoth-station/s2i-thoth-dev:latest
      workingDir: $(workspaces.data.path)
      env:
        - name: PIPELINE_NAME
          value: $(params.pipeline)
        - name: PIPELINERUN_NAME
          value: $(params.pipelineRun)
      script: |
        #!/opt/app-root/bin/python
        import os
        import time
        from prometheus_client import CollectorRegistry, Counter, Gauge, push_to_gateway

        PROMETHEUS_REGISTRY = CollectorRegistry()

        LABEL_KEYS = ["pipeline", "pipelinerun"]
        LABEL_VALUES = [os.getenv("PIPELINE_NAME"), os.getenv("PIPELINERUN_NAME")]

        SUBSYTEM_PREFIX = "meteor_pipelines_"

        METRICS = [
            Counter(
                f"{SUBSYTEM_PREFIX}images_total",
                "OCI images submitted for build.",
                LABEL_KEYS,
                registry=PROMETHEUS_REGISTRY,
            ),
            Counter(
                f"{SUBSYTEM_PREFIX}image_build_success_total",
                "OCI image build was successfull.",
                LABEL_KEYS,
                registry=PROMETHEUS_REGISTRY,
            ),
            Gauge(
                f"{SUBSYTEM_PREFIX}image_build_duration",
                "OCI images build time.",
                LABEL_KEYS,
                registry=PROMETHEUS_REGISTRY,
            ),
            Gauge(
                f"{SUBSYTEM_PREFIX}image_push_duration",
                "OCI image push time.",
                LABEL_KEYS,
                registry=PROMETHEUS_REGISTRY,
            ),
            Gauge(
                f"{SUBSYTEM_PREFIX}content_build_duration",
                "Content build time.",
                LABEL_KEYS,
                registry=PROMETHEUS_REGISTRY,
            ),
            Counter(
                f"{SUBSYTEM_PREFIX}image_analysis_total",
                "OCI image analysis attempted.",
                LABEL_KEYS,
                registry=PROMETHEUS_REGISTRY,
            ),
            Counter(
                f"{SUBSYTEM_PREFIX}image_analysis_success_total",
                "OCI image successfully submitted for analysis.",
                LABEL_KEYS,
                registry=PROMETHEUS_REGISTRY,
            ),
            Counter(
                f"{SUBSYTEM_PREFIX}image_analysis_failure_total",
                "OCI image failed to submit for analysis.",
                LABEL_KEYS,
                registry=PROMETHEUS_REGISTRY,
            ),
            Counter(
                f"{SUBSYTEM_PREFIX}image_build_log_analysis_total",
                "OCI image build log analysis attempted.",
                LABEL_KEYS,
                registry=PROMETHEUS_REGISTRY,
            ),
            Counter(
                f"{SUBSYTEM_PREFIX}image_build_log_analysis_success_total",
                "OCI image build log analysis submitted successfully.",
                LABEL_KEYS,
                registry=PROMETHEUS_REGISTRY,
            ),
            Counter(
                f"{SUBSYTEM_PREFIX}image_build_log_analysis_failure_total",
                "OCI image build log analysis failed to submit.",
                LABEL_KEYS,
                registry=PROMETHEUS_REGISTRY,
            ),
            Counter(
                f"{SUBSYTEM_PREFIX}image_build_log_analysis_skipped_total",
                "OCI image build log analysis skipped.",
                LABEL_KEYS,
                registry=PROMETHEUS_REGISTRY,
            ),
        ]

        # Python 3.8 workaround
        def removeprefix(text, prefix):
            return text[text.startswith(prefix) and len(prefix) :]


        for metric in METRICS:
            try:
                with open(
                    f".tekton_metrics/{removeprefix(metric._name, SUBSYTEM_PREFIX)}", "r"
                ) as f:
                    value = 1 if isinstance(metric, Counter) else float(f.read().strip())
                metric.labels(*LABEL_VALUES).inc(value)
                print(f"Found value for metric: {metric._name}")
            except Exception as e:
                print(f"Skipping metric (value not set): {metric._name} : {e}")


        try:
            print("Submitting metrics to Prometheus pushgateway")
            push_to_gateway(
                f"http://pushgateway:9091",
                job=os.getenv("PIPELINERUN_NAME"),
                registry=PROMETHEUS_REGISTRY,
            )
        except Exception as e:
            print(f"An error occurred pushing the metrics: {str(e)}")
